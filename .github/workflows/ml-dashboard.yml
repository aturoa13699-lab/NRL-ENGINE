name: ml-dashboard
on:
  schedule: [{ cron: "50 22 * * 2" }]   # Tue ~09:50 AEST
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  dashboard:
    # Run schedules only on default branch
    if: ${{ github.event_name != 'schedule' || github.ref == format('refs/heads/{0}', github.event.repository.default_branch) }}
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - name: Checkout source
        uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - name: Pull latest data branch (exports & odds)
        run: |
          set -e
          git fetch origin data || true
          mkdir -p data/exports data/sources reports
          if git rev-parse --verify origin/data >/dev/null 2>&1; then
            git worktree add --detach _data origin/data
            cp -r _data/data/exports/* data/exports/ 2>/dev/null || true
            cp -r _data/data/sources/* data/sources/ 2>/dev/null || true
          fi
          ls -lh data/exports || true
          ls -lh data/sources || true

      - name: Ensure training data exists (soft-fail with placeholder)
        id: datacheck
        run: |
          if [ ! -f data/exports/train_super_enriched_v2.csv ]; then
            echo "no_data=true" >> $GITHUB_OUTPUT
            echo "::warning::No train_super_enriched_v2.csv found in data/exports/; creating placeholder report."
          fi

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install ML deps
        run: |
          pip install -q "pandas>=2" "pyarrow" "fastparquet" \
                         "scikit-learn>=1.3" "scipy" "plotly" \
                         "papermill" "nbconvert" "jupyter" "jinja2"

      - name: Run anchored training (if data present)
        if: steps.datacheck.outputs.no_data != 'true'
        run: |
          python -m tools.train_market_anchor \
            --data data/exports/train_super_enriched_v2.csv \
            --odds data/sources/odds.csv \
            --calibrate isotonic | tee reports/metrics.json

      - name: Build minimal HTML dashboard
        run: |
          python - <<'PY'
          import json, datetime, pathlib
          rep = pathlib.Path("reports"); rep.mkdir(exist_ok=True, parents=True)
          metrics = {"note":"no data"}  # default
          p = rep/"metrics.json"
          if p.exists():
            try: metrics = json.loads(p.read_text())
            except Exception: pass
          now = datetime.datetime.utcnow().isoformat()+"Z"
          html = f"""<!doctype html>
          <meta charset="utf-8">
          <title>NRL Market-Anchored Dashboard</title>
          <style>
            body{{font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;font-size:15px;max-width:920px;margin:40px auto;padding:0 16px}}
            pre{{background:#f6f8fa;padding:12px;border-radius:6px;overflow:auto}}
            .card{{border:1px solid #e5e7eb;border-radius:10px;padding:16px;margin:14px 0}}
            h1{{margin:0 0 8px 0}}
          </style>
          <h1>NRL Market-Anchored Report</h1>
          <div class="card"><b>Generated:</b> {now}</div>
          <div class="card"><h3>Metrics</h3>
          <pre>{json.dumps(metrics, indent=2)}</pre></div>
          <p>Source: tools/train_market_anchor.py (isotonic calibration).</p>
          """
          (rep/"market_dashboard.html").write_text(html, encoding="utf-8")
          print("Wrote reports/market_dashboard.html")
          PY

      - name: (Optional) Execute notebook dashboard if present
        run: |
          if [ -f notebooks/60_market_anchored_training.ipynb ]; then
            echo '{"params":{}}' > params.json
            papermill notebooks/60_market_anchored_training.ipynb \
                      reports/60_market_anchored_out.ipynb -k python3 -f params.json || true
            jupyter nbconvert --to html --output-dir "reports" \
                      "reports/60_market_anchored_out.ipynb" || true
          else
            echo "No notebook found; using minimal HTML only."
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ml-dashboard
          path: reports/*
          retention-days: 14
          if-no-files-found: ignore

      - name: Publish dashboard to data branch
        if: always()
        env:
          BR: data
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Always start from latest remote state if it exists
          git fetch origin --prune
          if git ls-remote --exit-code --heads origin "$BR" >/dev/null 2>&1; then
            git checkout -B "$BR" "origin/$BR"
          else
            git checkout -B "$BR"
          fi

          mkdir -p reports/market
          TS=$(date -u +%Y%m%dT%H%M%SZ)
          mkdir -p "reports/market/${TS}"

          # Copy reports (handle both same-dir and parent-dir scenarios)
          SRC_DIR="reports"
          [ -d "../reports" ] && SRC_DIR="../reports"
          cp ${SRC_DIR}/*.html "reports/market/${TS}/" 2>/dev/null || true
          cp ${SRC_DIR}/*.json "reports/market/${TS}/" 2>/dev/null || true

          # Update latest pointers
          rm -f reports/market/latest.html reports/market/metrics.json 2>/dev/null || true
          if [ -f "${SRC_DIR}/market_dashboard.html" ]; then
            cp "${SRC_DIR}/market_dashboard.html" reports/market/latest.html
          fi
          [ -f "${SRC_DIR}/metrics.json" ] && cp "${SRC_DIR}/metrics.json" reports/market/metrics.json

          git add reports/market/* || true
          git commit -m "reports: market-anchored dashboard ${TS}" || echo "nothing to commit"

          # Push with retries to handle race conditions
          n=0
          until [ $n -ge 3 ]; do
            git fetch origin "$BR" 2>/dev/null || true
            if git push --force-with-lease origin HEAD:refs/heads/$BR 2>/dev/null; then
              echo "âœ… Pushed to ${BR}"
              break
            fi
            n=$((n+1))
            delay=$((n*3))
            echo "Push race; retrying in ${delay}s..."
            sleep $delay
            # Rebase on latest remote
            git fetch origin "$BR" 2>/dev/null || true
            git rebase "origin/$BR" 2>/dev/null || git rebase --abort 2>/dev/null || true
          done
          [ $n -lt 3 ] || echo "::warning::Push to data branch failed after retries"

      - name: Job Summary
        run: |
          echo "### ML Dashboard" >> $GITHUB_STEP_SUMMARY
          echo "- Reports artifact: **ml-dashboard**" >> $GITHUB_STEP_SUMMARY
          echo "- Data branch path: \`reports/market/latest.html\` and time-stamped folders" >> $GITHUB_STEP_SUMMARY
